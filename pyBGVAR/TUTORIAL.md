# pyBGVAR ì‹¤ì „ íŠœí† ë¦¬ì–¼

> GitHubì—ì„œ ì„¤ì¹˜í•œ pyBGVARë¥¼ ì‹¤ì œ ì—°êµ¬/ë¶„ì„ì— í™œìš©í•˜ëŠ” ì™„ë²½ ê°€ì´ë“œ

## ëª©ì°¨
1. [ì‹œì‘í•˜ê¸° ì „ì—](#1-ì‹œì‘í•˜ê¸°-ì „ì—)
2. [ì²« ë²ˆì§¸ í”„ë¡œì íŠ¸: ê°„ë‹¨í•œ GVAR ë¶„ì„](#2-ì²«-ë²ˆì§¸-í”„ë¡œì íŠ¸-ê°„ë‹¨í•œ-gvar-ë¶„ì„)
3. [ì‹¤ì œ ë°ì´í„°ë¡œ ë¶„ì„í•˜ê¸°](#3-ì‹¤ì œ-ë°ì´í„°ë¡œ-ë¶„ì„í•˜ê¸°)
4. [ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©](#4-ê³ ê¸‰-ê¸°ëŠ¥-í™œìš©)
5. [ê²°ê³¼ í•´ì„ ë° ë³´ê³ ](#5-ê²°ê³¼-í•´ì„-ë°-ë³´ê³ )
6. [ì„±ëŠ¥ ìµœì í™”](#6-ì„±ëŠ¥-ìµœì í™”)

---

## 1. ì‹œì‘í•˜ê¸° ì „ì—

### 1-1. í™˜ê²½ ì¤€ë¹„ ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# 1. Python ë²„ì „ í™•ì¸ (3.8 ì´ìƒ)
python --version

# 2. ê°€ìƒ í™˜ê²½ ìƒì„± ë° í™œì„±í™”
python -m venv myproject_env
source myproject_env/bin/activate  # Windows: myproject_env\Scripts\activate

# 3. pyBGVAR ì„¤ì¹˜
pip install git+https://github.com/[ì‚¬ìš©ìëª…]/pyBGVAR.git

# 4. ì„¤ì¹˜ í™•ì¸
python -c "import pyBGVAR; print('âœ… ì„¤ì¹˜ ì„±ê³µ!')"
```

### 1-2. í”„ë¡œì íŠ¸ í´ë” êµ¬ì¡°

```
my_bgvar_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/              # ì›ë³¸ ë°ì´í„°
â”‚   â””â”€â”€ processed/        # ì „ì²˜ë¦¬ëœ ë°ì´í„°
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_data_prep.py   # ë°ì´í„° ì¤€ë¹„
â”‚   â”œâ”€â”€ 02_estimation.py  # ëª¨ë¸ ì¶”ì •
â”‚   â”œâ”€â”€ 03_analysis.py    # ë¶„ì„ ë° ì‹œê°í™”
â”‚   â””â”€â”€ utils.py          # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ models/           # ì €ì¥ëœ ëª¨ë¸
â”‚   â”œâ”€â”€ figures/          # ê·¸ë˜í”„
â”‚   â””â”€â”€ tables/           # í‘œ
â”œâ”€â”€ notebooks/            # Jupyter notebooks
â””â”€â”€ requirements.txt
```

---

## 2. ì²« ë²ˆì§¸ í”„ë¡œì íŠ¸: ê°„ë‹¨í•œ GVAR ë¶„ì„

### 2-1. ë°ì´í„° ì¤€ë¹„ (01_data_prep.py)

```python
"""
ë°ì´í„° ì¤€ë¹„ ìŠ¤í¬ë¦½íŠ¸
ê°„ë‹¨í•œ ì˜ˆì œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
"""
import numpy as np
import pandas as pd
import pickle

def create_example_data():
    """ì˜ˆì œ ë°ì´í„° ìƒì„±"""
    np.random.seed(42)
    
    # ì‹œë®¬ë ˆì´ì…˜ íŒŒë¼ë¯¸í„°
    T = 200  # ì‹œê³„ì—´ ê¸¸ì´ (ì•½ 16ë…„ ë¶„ê¸° ë°ì´í„°)
    countries = ['US', 'EA', 'UK', 'JP']
    variables = ['y', 'Dp', 'stir']  # GDP, ì¸í”Œë ˆì´ì…˜, ë‹¨ê¸°ê¸ˆë¦¬
    
    # êµ­ê°€ë³„ ë°ì´í„° ìƒì„±
    data_dict = {}
    for country in countries:
        # GDP: ì¶”ì„¸ + ëœë¤ì›Œí¬
        y = 100 + np.linspace(0, 50, T) + np.random.randn(T).cumsum() * 0.5
        
        # ì¸í”Œë ˆì´ì…˜: í‰ê· íšŒê·€ ê³¼ì •
        Dp = 2 + np.random.randn(T) * 0.5
        for t in range(1, T):
            Dp[t] = 0.7 * Dp[t-1] + 0.3 * 2 + np.random.randn() * 0.5
        
        # ë‹¨ê¸°ê¸ˆë¦¬: GDPì™€ ì¸í”Œë ˆì´ì…˜ì˜ í•¨ìˆ˜
        stir = 1 + 0.01 * (y - y[0]) + 0.5 * Dp + np.random.randn(T) * 0.3
        
        data_dict[country] = pd.DataFrame({
            'y': y,
            'Dp': Dp,
            'stir': stir
        })
    
    return data_dict, countries

def create_weight_matrix(countries):
    """ê°€ì¤‘ì¹˜ í–‰ë ¬ ìƒì„± (ë¬´ì—­ ê°€ì¤‘ì¹˜ ì‹œë®¬ë ˆì´ì…˜)"""
    N = len(countries)
    
    # ì˜ˆì œ: ë¬´ì—­ ê°€ì¤‘ì¹˜ (ì‹¤ì œë¡œëŠ” ì‹¤ì œ ë°ì´í„° ì‚¬ìš©)
    W = np.array([
        [0.0, 0.4, 0.3, 0.3],  # US
        [0.5, 0.0, 0.3, 0.2],  # EA
        [0.4, 0.4, 0.0, 0.2],  # UK
        [0.3, 0.3, 0.2, 0.0]   # JP
    ])
    
    # ì •ê·œí™” (ê° í–‰ì˜ í•©ì´ 1)
    W = W / W.sum(axis=1, keepdims=True)
    
    return pd.DataFrame(W, index=countries, columns=countries)

if __name__ == '__main__':
    print("=" * 60)
    print("ë°ì´í„° ì¤€ë¹„")
    print("=" * 60)
    
    # ë°ì´í„° ìƒì„±
    data_dict, countries = create_example_data()
    W = create_weight_matrix(countries)
    
    # ì €ì¥
    with open('data/processed/data_dict.pkl', 'wb') as f:
        pickle.dump(data_dict, f)
    
    W.to_csv('data/processed/weight_matrix.csv')
    
    print(f"\nâœ… ë°ì´í„° ìƒì„± ì™„ë£Œ")
    print(f"   - êµ­ê°€ ìˆ˜: {len(countries)}")
    print(f"   - ë³€ìˆ˜ ìˆ˜: {data_dict['US'].shape[1]}")
    print(f"   - ì‹œê³„ì—´ ê¸¸ì´: {data_dict['US'].shape[0]}")
    print(f"\nê°€ì¤‘ì¹˜ í–‰ë ¬:")
    print(W)
```

### 2-2. ëª¨ë¸ ì¶”ì • (02_estimation.py)

```python
"""
BGVAR ëª¨ë¸ ì¶”ì • ìŠ¤í¬ë¦½íŠ¸
"""
import pickle
import pandas as pd
from pyBGVAR import BGVAR
import time

def estimate_bgvar_model(data_dict, W, draws=5000, burnin=5000):
    """BGVAR ëª¨ë¸ ì¶”ì •"""
    print("=" * 60)
    print("BGVAR ëª¨ë¸ ì¶”ì • ì‹œì‘")
    print("=" * 60)
    
    start_time = time.time()
    
    # ëª¨ë¸ ì¶”ì •
    model = BGVAR(
        Data=data_dict,
        W=W,
        plag=2,              # ì‹œì°¨ 2
        draws=draws,         # MCMC ì¶”ì¶œ ìˆ˜
        burnin=burnin,       # Burn-in
        prior="NG",          # Normal-Gamma prior
        SV=True,             # Stochastic Volatility
        hold_out=0,          # Hold-out ìƒ˜í”Œ
        eigen=True,          # ì•ˆì •ì„± ê²€ì‚¬
        verbose=True
    )
    
    elapsed = time.time() - start_time
    print(f"\nâœ… ì¶”ì • ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)")
    
    return model

def save_model_summary(model, filename='results/models/model_summary.txt'):
    """ëª¨ë¸ ìš”ì•½ ì €ì¥"""
    summary = model.summary()
    
    with open(filename, 'w', encoding='utf-8') as f:
        f.write("=" * 60 + "\n")
        f.write("BGVAR ëª¨ë¸ ìš”ì•½\n")
        f.write("=" * 60 + "\n\n")
        f.write(f"êµ­ê°€ ìˆ˜: {model.N}\n")
        f.write(f"ì „ì—­ ë³€ìˆ˜ ìˆ˜: {model.xglobal.shape[1]}\n")
        f.write(f"ì‹œê³„ì—´ ê¸¸ì´: {model.xglobal.shape[0]}\n")
        f.write(f"Prior: {model.prior}\n")
        f.write(f"MCMC ì¶”ì¶œ ìˆ˜: {model.args.get('thindraws', 0)}\n\n")
        
    print(f"âœ… ëª¨ë¸ ìš”ì•½ ì €ì¥: {filename}")

if __name__ == '__main__':
    # ë°ì´í„° ë¡œë“œ
    with open('data/processed/data_dict.pkl', 'rb') as f:
        data_dict = pickle.load(f)
    W = pd.read_csv('data/processed/weight_matrix.csv', index_col=0)
    
    # ëª¨ë¸ ì¶”ì • (í…ŒìŠ¤íŠ¸ìš© ì‘ì€ draws)
    model = estimate_bgvar_model(data_dict, W, draws=1000, burnin=1000)
    
    # ëª¨ë¸ ì €ì¥
    with open('results/models/bgvar_model.pkl', 'wb') as f:
        pickle.dump(model, f)
    print("âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ: results/models/bgvar_model.pkl")
    
    # ìš”ì•½ ì €ì¥
    save_model_summary(model)
```

### 2-3. ë¶„ì„ ë° ì‹œê°í™” (03_analysis.py)

```python
"""
IRF ë° FEVD ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
"""
import pickle
import numpy as np
import matplotlib.pyplot as plt
from pyBGVAR import get_shockinfo, compute_fevd, plot

def compute_irf(model, shock_var='US.stir', n_ahead=24):
    """IRF ê³„ì‚°"""
    print(f"\nIRF ê³„ì‚°: {shock_var} ì¶©ê²©")
    
    # Cholesky ì‹ë³„
    shockinfo = get_shockinfo(ident="chol", nr_rows=1)
    shockinfo.loc[0, 'shock'] = shock_var
    shockinfo.loc[0, 'scale'] = 1.0  # 1 í‘œì¤€í¸ì°¨
    
    irf_result = model.irf(n_ahead=n_ahead, shockinfo=shockinfo, verbose=True)
    
    return irf_result

def plot_irf_results(irf_result, shock_name='US.stir'):
    """IRF í”Œë¡¯"""
    fig = plot.plot_irf(
        irf_result,
        resp=['US.y', 'EA.y', 'UK.y', 'JP.y'],
        shock=0,
        quantiles=[0.16, 0.5, 0.84]
    )
    
    plt.suptitle(f'Impulse Response to {shock_name} Shock', y=1.02)
    plt.tight_layout()
    plt.savefig(f'results/figures/irf_{shock_name.replace(".", "_")}.png', 
                dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… IRF í”Œë¡¯ ì €ì¥: results/figures/irf_{shock_name.replace('.', '_')}.png")

def compute_and_plot_fevd(irf_result, var='US.y'):
    """FEVD ê³„ì‚° ë° í”Œë¡¯"""
    print(f"\nFEVD ê³„ì‚°: {var}")
    
    fevd_result = compute_fevd(irf_result, var_slct=[var])
    
    fig = plot.plot_fevd(fevd_result, resp=var, k_max=10)
    plt.tight_layout()
    plt.savefig(f'results/figures/fevd_{var.replace(".", "_")}.png', 
                dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… FEVD í”Œë¡¯ ì €ì¥: results/figures/fevd_{var.replace('.', '_')}.png")
    
    return fevd_result

if __name__ == '__main__':
    # ëª¨ë¸ ë¡œë“œ
    with open('results/models/bgvar_model.pkl', 'rb') as f:
        model = pickle.load(f)
    
    print("=" * 60)
    print("IRF ë° FEVD ë¶„ì„")
    print("=" * 60)
    
    # ë¯¸êµ­ ê¸ˆë¦¬ ì¶©ê²© IRF
    irf_us_stir = compute_irf(model, shock_var='US.stir', n_ahead=24)
    plot_irf_results(irf_us_stir, shock_name='US.stir')
    
    # ë¯¸êµ­ GDP FEVD
    fevd_us_y = compute_and_plot_fevd(irf_us_stir, var='US.y')
    
    print("\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
```

---

## 3. ì‹¤ì œ ë°ì´í„°ë¡œ ë¶„ì„í•˜ê¸°

### 3-1. Excel ë°ì´í„° ì½ê¸°

```python
"""
ì‹¤ì œ ë°ì´í„°ë¡œ ì‘ì—…í•˜ê¸°
"""
import pandas as pd
from pyBGVAR import excel_to_list, matrix_to_list

# ë°©ë²• 1: Excel íŒŒì¼ ì§ì ‘ ì½ê¸° (ì‹œíŠ¸ë³„ë¡œ êµ­ê°€)
# Excel í˜•ì‹: ê° ì‹œíŠ¸ê°€ êµ­ê°€ëª…, ì»¬ëŸ¼ì´ ë³€ìˆ˜ëª…
data_dict = excel_to_list('data/raw/economic_data.xlsx')

# ë°©ë²• 2: CSV ì½ê¸° í›„ ë³€í™˜
# CSV í˜•ì‹: ì»¬ëŸ¼ëª…ì´ 'COUNTRY.VARIABLE' í˜•íƒœ
data_matrix = pd.read_csv('data/raw/economic_data.csv', index_col=0)
data_dict = matrix_to_list(data_matrix)

print("êµ­ê°€ ëª©ë¡:", list(data_dict.keys()))
print("ë³€ìˆ˜ ëª©ë¡:", list(data_dict[list(data_dict.keys())[0]].columns))
```

### 3-2. ë°ì´í„° ì „ì²˜ë¦¬

```python
"""
ë°ì´í„° ì „ì²˜ë¦¬ ë° ê²€ì¦
"""
import numpy as np
import pandas as pd

def check_missing_values(data_dict):
    """ê²°ì¸¡ì¹˜ í™•ì¸"""
    for country, df in data_dict.items():
        missing = df.isnull().sum()
        if missing.any():
            print(f"âš ï¸  {country}: ê²°ì¸¡ì¹˜ ë°œê²¬")
            print(missing[missing > 0])
    print("âœ… ê²°ì¸¡ì¹˜ ê²€ì‚¬ ì™„ë£Œ")

def check_stationarity(data_dict):
    """ì •ìƒì„± ëŒ€ëµ í™•ì¸ (ADF í…ŒìŠ¤íŠ¸)"""
    from scipy import stats
    
    for country, df in data_dict.items():
        for col in df.columns:
            # ê°„ë‹¨í•œ ì¶”ì„¸ ê²€ì‚¬
            x = np.arange(len(df))
            slope, _, _, p_value, _ = stats.linregress(x, df[col])
            
            if p_value < 0.05 and abs(slope) > 0.01:
                print(f"âš ï¸  {country}.{col}: ê°•í•œ ì¶”ì„¸ ì¡´ì¬ (ì°¨ë¶„ ê³ ë ¤)")
    
    print("âœ… ì •ìƒì„± ê²€ì‚¬ ì™„ë£Œ")

def transform_data(data_dict, transformations):
    """
    ë°ì´í„° ë³€í™˜ ì ìš©
    transformations: dict of dict
        ì˜ˆ: {'US': {'y': 'log_diff', 'Dp': 'none', 'stir': 'none'}}
    """
    transformed = {}
    
    for country, df in data_dict.items():
        transformed[country] = df.copy()
        
        if country in transformations:
            for var, trans in transformations[country].items():
                if trans == 'log':
                    transformed[country][var] = np.log(df[var])
                elif trans == 'log_diff':
                    transformed[country][var] = np.log(df[var]).diff()
                elif trans == 'diff':
                    transformed[country][var] = df[var].diff()
        
        # ê²°ì¸¡ì¹˜ ì œê±° (ì°¨ë¶„ ë“±ìœ¼ë¡œ ìƒê¸´)
        transformed[country] = transformed[country].dropna()
    
    return transformed

# ì‹¤í–‰ ì˜ˆì œ
if __name__ == '__main__':
    # ë°ì´í„° ê²€ì¦
    check_missing_values(data_dict)
    check_stationarity(data_dict)
    
    # ë³€í™˜ ì •ì˜
    transformations = {
        'US': {'y': 'log_diff', 'Dp': 'none', 'stir': 'none'},
        'EA': {'y': 'log_diff', 'Dp': 'none', 'stir': 'none'},
        # ... ë‹¤ë¥¸ êµ­ê°€
    }
    
    # ë³€í™˜ ì ìš©
    data_dict_transformed = transform_data(data_dict, transformations)
```

### 3-3. ì‹¤ì œ ê°€ì¤‘ì¹˜ í–‰ë ¬ ìƒì„±

```python
"""
ì‹¤ì œ ë¬´ì—­ ë°ì´í„°ë¡œ ê°€ì¤‘ì¹˜ í–‰ë ¬ ìƒì„±
"""
import pandas as pd
import numpy as np

def create_trade_weights(trade_matrix):
    """
    ë¬´ì—­ ë°ì´í„°ë¡œ ê°€ì¤‘ì¹˜ í–‰ë ¬ ìƒì„±
    
    Parameters:
    -----------
    trade_matrix : DataFrame
        í–‰: ìˆ˜ì¶œêµ­, ì—´: ìˆ˜ì…êµ­
        ê°’: ë¬´ì—­ëŸ‰ (ì˜ˆ: ë°±ë§Œ ë‹¬ëŸ¬)
    
    Returns:
    --------
    W : DataFrame
        ê°€ì¤‘ì¹˜ í–‰ë ¬ (í–‰ì˜ í•© = 1, ëŒ€ê°ì„  = 0)
    """
    # ì–‘ë°©í–¥ ë¬´ì—­ (ìˆ˜ì¶œ + ìˆ˜ì…)
    total_trade = trade_matrix + trade_matrix.T
    
    # ëŒ€ê°ì„  0
    np.fill_diagonal(total_trade.values, 0)
    
    # ì •ê·œí™”
    row_sums = total_trade.sum(axis=1)
    W = total_trade.div(row_sums, axis=0)
    
    return W

# ì˜ˆì œ: ë¬´ì—­ ë°ì´í„° ì½ê¸°
trade_data = pd.read_csv('data/raw/bilateral_trade.csv', index_col=0)
W = create_trade_weights(trade_data)

print("ê°€ì¤‘ì¹˜ í–‰ë ¬:")
print(W)
print("\ní–‰ì˜ í•© (ëª¨ë‘ 1ì´ì–´ì•¼ í•¨):")
print(W.sum(axis=1))
```

---

## 4. ê³ ê¸‰ ê¸°ëŠ¥ í™œìš©

### 4-1. ë¶€í˜¸ ì œì•½ IRF

```python
"""
ë¶€í˜¸ ì œì•½ì„ ì‚¬ìš©í•œ ì¶©ê²© ì‹ë³„
ì˜ˆ: ê¸´ì¶• í†µí™”ì •ì±… ì¶©ê²©
"""
from pyBGVAR import get_shockinfo, add_shockinfo

# ê¸´ì¶• í†µí™”ì •ì±… ì¶©ê²©:
# - ê¸ˆë¦¬ ìƒìŠ¹ (+)
# - GDP í•˜ë½ (-)
# - ì¸í”Œë ˆì´ì…˜ í•˜ë½ (-)

shockinfo = get_shockinfo(ident="sign", nr_rows=1)
shockinfo = add_shockinfo(
    shockinfo,
    shock='US.stir',              # ì¶©ê²© ë³€ìˆ˜: ë¯¸êµ­ ê¸ˆë¦¬
    restriction=['US.stir', 'US.y', 'US.Dp'],  # ì œì•½í•  ë³€ìˆ˜ë“¤
    sign=['+', '-', '-'],         # ë¶€í˜¸ ì œì•½
    horizon=4,                    # 4ê¸°ê¹Œì§€ ì œì•½
    prob=0.65,                    # 65% í™•ë¥ ë¡œ ë§Œì¡±
    scale=1,                      # í¬ê¸°
    scale_horizon=0               # ì¦‰ê° ë°˜ì‘
)

# IRF ê³„ì‚°
irf_monetary = model.irf(n_ahead=24, shockinfo=shockinfo, verbose=True)

# í”Œë¡¯
plot.plot_irf(irf_monetary, resp=['US.stir', 'US.y', 'US.Dp'], shock=0)
plt.suptitle('Contractionary Monetary Policy Shock (Sign Restrictions)')
plt.savefig('results/figures/irf_monetary_policy.png', dpi=300, bbox_inches='tight')
plt.close()
```

### 4-2. ì¡°ê±´ë¶€ ì˜ˆì¸¡

```python
"""
ì¡°ê±´ë¶€ ì˜ˆì¸¡: íŠ¹ì • ë³€ìˆ˜ë¥¼ ê³ ì •í•œ ìƒíƒœì—ì„œ ì˜ˆì¸¡
ì˜ˆ: ê¸ˆë¦¬ ê²½ë¡œë¥¼ ê³ ì •í•˜ê³  GDPì™€ ì¸í”Œë ˆì´ì…˜ ì˜ˆì¸¡
"""
import numpy as np

def conditional_forecast(model, fixed_vars, fixed_paths, n_ahead=8):
    """
    ì¡°ê±´ë¶€ ì˜ˆì¸¡
    
    Parameters:
    -----------
    model : BGVAR object
    fixed_vars : list
        ê³ ì •í•  ë³€ìˆ˜ëª… ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['US.stir'])
    fixed_paths : dict
        ë³€ìˆ˜ë³„ ê³ ì • ê²½ë¡œ (ì˜ˆ: {'US.stir': [2.0, 2.5, 3.0, ...]})
    n_ahead : int
        ì˜ˆì¸¡ ê¸°ê°„
    """
    # ì œì•½ í–‰ë ¬ ì´ˆê¸°í™”
    K = model.xglobal.shape[1]
    constr = np.zeros((n_ahead, K))
    
    # ê³ ì • ë³€ìˆ˜ ê²½ë¡œ ì„¤ì •
    for var, path in fixed_paths.items():
        var_idx = list(model.xglobal.columns).index(var)
        constr[:, var_idx] = path
    
    # ì¡°ê±´ë¶€ ì˜ˆì¸¡
    fcast_cond = model.predict(
        n_ahead=n_ahead,
        constr=constr,
        save_store=True,
        verbose=True
    )
    
    return fcast_cond

# ì‹¤í–‰ ì˜ˆì œ
fixed_paths = {
    'US.stir': np.linspace(2.0, 4.0, 8)  # ê¸ˆë¦¬ 2%ì—ì„œ 4%ë¡œ ì¦ê°€
}

fcast_cond = conditional_forecast(
    model,
    fixed_vars=['US.stir'],
    fixed_paths=fixed_paths,
    n_ahead=8
)

# í”Œë¡¯
plot.plot_pred(fcast_cond, resp=['US.y', 'US.Dp', 'US.stir'], cut=20)
plt.suptitle('Conditional Forecast (Fixed Interest Rate Path)')
plt.savefig('results/figures/conditional_forecast.png', dpi=300, bbox_inches='tight')
plt.close()
```

### 4-3. ëª¨ë¸ ë¹„êµ

```python
"""
ë‹¤ì–‘í•œ priorì™€ ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ë¹„êµ
"""
from pyBGVAR import BGVAR

def compare_models(data_dict, W, specs):
    """
    ì—¬ëŸ¬ ëª¨ë¸ ìŠ¤í™ ë¹„êµ
    
    Parameters:
    -----------
    specs : list of dict
        ê° ëª¨ë¸ ìŠ¤í™ (ì˜ˆ: [{'prior': 'MN', 'SV': False}, ...])
    """
    results = {}
    
    for i, spec in enumerate(specs):
        print(f"\nëª¨ë¸ {i+1}: {spec}")
        
        model = BGVAR(
            Data=data_dict,
            W=W,
            plag=spec.get('plag', 2),
            draws=spec.get('draws', 5000),
            burnin=spec.get('burnin', 5000),
            prior=spec['prior'],
            SV=spec.get('SV', True),
            verbose=False
        )
        
        # DIC ê³„ì‚°
        dic_result = model.dic()
        
        results[f"Model_{i+1}_{spec['prior']}"] = {
            'model': model,
            'DIC': dic_result['DIC'],
            'pD': dic_result['pD'],
            'spec': spec
        }
        
        print(f"  DIC: {dic_result['DIC']:.2f}")
        print(f"  pD: {dic_result['pD']:.2f}")
    
    return results

# ì‹¤í–‰
specs = [
    {'prior': 'MN', 'SV': False},     # Minnesota, no SV
    {'prior': 'SSVS', 'SV': True},    # SSVS with SV
    {'prior': 'NG', 'SV': True},      # Normal-Gamma with SV
]

model_comparison = compare_models(data_dict, W, specs)

# ìµœì  ëª¨ë¸ ì„ íƒ (DIC ê¸°ì¤€)
best_model_name = min(model_comparison, key=lambda k: model_comparison[k]['DIC'])
best_model = model_comparison[best_model_name]['model']

print(f"\nâœ… ìµœì  ëª¨ë¸: {best_model_name}")
```

---

## 5. ê²°ê³¼ í•´ì„ ë° ë³´ê³ 

### 5-1. IRF í•´ì„ ê°€ì´ë“œ

```python
"""
IRF ê²°ê³¼ í•´ì„ ë° í‘œ ìƒì„±
"""
import pandas as pd

def extract_irf_table(irf_result, horizon=[0, 1, 4, 8, 12], 
                     responses=['US.y', 'EA.y'], shock_name='US.stir'):
    """
    IRF ê²°ê³¼ë¥¼ í‘œë¡œ ì •ë¦¬
    """
    irf_median = irf_result['posterior']['IRF.Median']
    irf_lower = irf_result['posterior']['IRF.LB']
    irf_upper = irf_result['posterior']['IRF.UB']
    
    # ì¶©ê²© ì¸ë±ìŠ¤
    shock_idx = 0  # ì²« ë²ˆì§¸ ì¶©ê²©
    
    # í‘œ ìƒì„±
    table_data = []
    for resp in responses:
        resp_idx = list(irf_result['posterior']['variables']).index(resp)
        
        for h in horizon:
            median = irf_median[shock_idx, resp_idx, h]
            lower = irf_lower[shock_idx, resp_idx, h]
            upper = irf_upper[shock_idx, resp_idx, h]
            
            table_data.append({
                'Response': resp,
                'Horizon': h,
                'Median': f"{median:.4f}",
                '16% CI': f"{lower:.4f}",
                '84% CI': f"{upper:.4f}"
            })
    
    df = pd.DataFrame(table_data)
    return df

# í‘œ ìƒì„± ë° ì €ì¥
irf_table = extract_irf_table(irf_us_stir)
irf_table.to_csv('results/tables/irf_summary.csv', index=False)
irf_table.to_latex('results/tables/irf_summary.tex', index=False)

print("âœ… IRF í‘œ ì €ì¥ ì™„ë£Œ")
print(irf_table)
```

### 5-2. ë…¼ë¬¸ìš© ê·¸ë˜í”„ ìƒì„±

```python
"""
ì¶œíŒìš© ê³ í’ˆì§ˆ ê·¸ë˜í”„
"""
import matplotlib.pyplot as plt
import seaborn as sns

# ìŠ¤íƒ€ì¼ ì„¤ì •
sns.set_style("whitegrid")
plt.rcParams['font.size'] = 12
plt.rcParams['axes.labelsize'] = 14
plt.rcParams['axes.titlesize'] = 14
plt.rcParams['figure.figsize'] = (12, 8)

def publication_quality_irf(irf_result, responses, shock_name, 
                           save_path='results/figures/irf_publication.pdf'):
    """
    ì¶œíŒìš© IRF í”Œë¡¯
    """
    n_resp = len(responses)
    fig, axes = plt.subplots(2, 2, figsize=(12, 10))
    axes = axes.flatten()
    
    irf_median = irf_result['posterior']['IRF.Median']
    irf_lower = irf_result['posterior']['IRF.LB']
    irf_upper = irf_result['posterior']['IRF.UB']
    
    horizons = np.arange(irf_median.shape[2])
    shock_idx = 0
    
    for i, resp in enumerate(responses):
        ax = axes[i]
        resp_idx = list(irf_result['posterior']['variables']).index(resp)
        
        median = irf_median[shock_idx, resp_idx, :]
        lower = irf_lower[shock_idx, resp_idx, :]
        upper = irf_upper[shock_idx, resp_idx, :]
        
        # í”Œë¡¯
        ax.plot(horizons, median, 'b-', linewidth=2, label='Median')
        ax.fill_between(horizons, lower, upper, alpha=0.3, color='blue')
        ax.axhline(y=0, color='black', linestyle='--', linewidth=1)
        ax.set_xlabel('Horizon (Quarters)')
        ax.set_ylabel('Response')
        ax.set_title(f'{resp}')
        ax.grid(True, alpha=0.3)
        ax.legend()
    
    plt.suptitle(f'Impulse Responses to {shock_name} Shock', 
                 fontsize=16, y=1.00)
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    
    print(f"âœ… ì¶œíŒìš© ê·¸ë˜í”„ ì €ì¥: {save_path}")

# ì‹¤í–‰
publication_quality_irf(
    irf_us_stir, 
    responses=['US.y', 'US.Dp', 'EA.y', 'EA.Dp'],
    shock_name='US Interest Rate'
)
```

---

## 6. ì„±ëŠ¥ ìµœì í™”

### 6-1. ëŒ€ê·œëª¨ ëª¨ë¸ ìµœì í™”

```python
"""
ëŒ€ê·œëª¨ GVAR ëª¨ë¸ ìµœì í™” íŒ
"""

# 1. Thinning ì‚¬ìš© (ë©”ëª¨ë¦¬ ì ˆì•½)
model = BGVAR(
    Data=data_dict,
    W=W,
    plag=2,
    draws=20000,    # ë§ì€ draws
    burnin=10000,
    thin=10,        # 10ê°œ ì¤‘ 1ê°œë§Œ ì €ì¥ -> ì‹¤ì œ 2000ê°œ ì €ì¥
    prior="NG",
    SV=True
)

# 2. SV ë¹„í™œì„±í™” (ì†ë„ í–¥ìƒ)
model_fast = BGVAR(
    Data=data_dict,
    W=W,
    plag=2,
    draws=5000,
    burnin=5000,
    prior="MN",     # Minnesotaê°€ ê°€ì¥ ë¹ ë¦„
    SV=False,       # SV ë¹„í™œì„±í™”
)

# 3. ì˜ˆì¸¡ ì‹œ ë©”ëª¨ë¦¬ ì ˆì•½
fcast = model.predict(
    n_ahead=8,
    save_store=False,  # ì‚¬í›„ ë¶„í¬ ì €ì¥ ì•ˆí•¨
    verbose=False
)

# 4. IRF ê³„ì‚° ì‹œ ë³€ìˆ˜ ì„ íƒ
# ëª¨ë“  ë³€ìˆ˜ ëŒ€ì‹  ê´€ì‹¬ ë³€ìˆ˜ë§Œ
irf_result = compute_fevd(
    irf_result,
    var_slct=['US.y', 'US.Dp', 'US.stir']  # ì¼ë¶€ ë³€ìˆ˜ë§Œ
)
```

### 6-2. ë³‘ë ¬ ì²˜ë¦¬ (í–¥í›„ ì§€ì› ì˜ˆì •)

```python
"""
ë³‘ë ¬ ì²˜ë¦¬ ì˜ˆì‹œ (í–¥í›„ ë²„ì „ì—ì„œ ì§€ì› ì˜ˆì •)
"""
# # ì—¬ëŸ¬ ëª¨ë¸ì„ ë³‘ë ¬ë¡œ ì¶”ì •
# from joblib import Parallel, delayed
# 
# def estimate_single_model(spec):
#     return BGVAR(Data=data_dict, W=W, **spec)
# 
# specs = [
#     {'prior': 'MN', 'draws': 5000, 'burnin': 5000},
#     {'prior': 'SSVS', 'draws': 5000, 'burnin': 5000},
#     {'prior': 'NG', 'draws': 5000, 'burnin': 5000},
# ]
# 
# models = Parallel(n_jobs=3)(delayed(estimate_single_model)(spec) for spec in specs)
```

---

## ë¶€ë¡: ìœ ìš©í•œ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜

### A. ê²°ê³¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±

```python
"""
ìë™ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
"""
import datetime

def generate_report(model, irf_results, fevd_results, output_file='results/report.txt'):
    """
    ë¶„ì„ ê²°ê³¼ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    """
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("=" * 80 + "\n")
        f.write("BGVAR ë¶„ì„ ê²°ê³¼ ë¦¬í¬íŠ¸\n")
        f.write("=" * 80 + "\n")
        f.write(f"ìƒì„± ì¼ì‹œ: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # ëª¨ë¸ ì •ë³´
        f.write("1. ëª¨ë¸ ì •ë³´\n")
        f.write("-" * 80 + "\n")
        f.write(f"   - êµ­ê°€ ìˆ˜: {model.N}\n")
        f.write(f"   - ë³€ìˆ˜ ìˆ˜: {model.xglobal.shape[1]}\n")
        f.write(f"   - ì‹œê³„ì—´ ê¸¸ì´: {model.xglobal.shape[0]}\n")
        f.write(f"   - Prior: {model.prior}\n")
        f.write(f"   - MCMC ì¶”ì¶œ ìˆ˜: {model.args.get('thindraws', 0)}\n\n")
        
        # DIC
        dic_result = model.dic()
        f.write("2. ëª¨ë¸ ì„ íƒ ê¸°ì¤€\n")
        f.write("-" * 80 + "\n")
        f.write(f"   - DIC: {dic_result['DIC']:.2f}\n")
        f.write(f"   - pD: {dic_result['pD']:.2f}\n\n")
        
        # ìˆ˜ë ´ ì§„ë‹¨
        from pyBGVAR import conv_diag
        conv_result = conv_diag(model)
        f.write("3. ìˆ˜ë ´ ì§„ë‹¨\n")
        f.write("-" * 80 + "\n")
        f.write(f"   - Geweke ê²€ì • í†µê³¼ìœ¨: {conv_result['perc']}\n\n")
        
        f.write("4. ìƒì„±ëœ ê·¸ë˜í”„\n")
        f.write("-" * 80 + "\n")
        f.write("   - results/figures/irf_*.png\n")
        f.write("   - results/figures/fevd_*.png\n")
        f.write("   - results/figures/forecast_*.png\n\n")
        
    print(f"âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ: {output_file}")

# ì‹¤í–‰
generate_report(model, irf_us_stir, fevd_us_y)
```

---

## ë‹¤ìŒ ë‹¨ê³„

âœ… íŠœí† ë¦¬ì–¼ ì™„ë£Œ í›„:
1. **ìì‹ ì˜ ë°ì´í„°ë¡œ ì ìš©**
2. **ë‹¤ì–‘í•œ ì‹ë³„ ì „ëµ ì‹œë„** (Cholesky vs Sign restrictions)
3. **ëª¨ë¸ ìŠ¤í™ ë¹„êµ** (ë‹¤ì–‘í•œ prior, SV on/off)
4. **ê²°ê³¼ë¥¼ ë…¼ë¬¸/ë³´ê³ ì„œì— í™œìš©**

## ì¶”ê°€ ìë£Œ

- **[QUICKSTART.md](QUICKSTART.md)**: ë¹ ë¥¸ ì°¸ì¡°
- **[GITHUB_INSTALLATION_GUIDE.md](GITHUB_INSTALLATION_GUIDE.md)**: ì„¤ì¹˜ ë¬¸ì œ í•´ê²°
- **[ì›ë³¸ R íŒ¨í‚¤ì§€ ë…¼ë¬¸](https://www.jstatsoft.org/article/view/v104i09)**: ì´ë¡  ë° ë°©ë²•ë¡ 

---

**ì¦ê±°ìš´ ë¶„ì„ ë˜ì„¸ìš”!** ğŸ¯

